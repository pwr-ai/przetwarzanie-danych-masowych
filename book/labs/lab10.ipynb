{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Laboratorium 10\n",
    "\n",
    "## Uczenie i wybór modelu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dzisiejszym laboratorium kontynuujemy budowanie spójnego potoku masowego przetwarzania danych. Ostatnio zaimplementowaliśmy mechanizm wektoryzacji wraz z możliwością eksploracji danych. \n",
    "\n",
    "Dzisiaj zajmiemy się przygotowaniem uczenia oraz wyboru modeli uczenia maszynowego. \n",
    "\n",
    "Diagram planowanego systemu wygląda następująco:  \n",
    "![image](../data/project_flow_chart_L10.png)\n",
    "\n",
    "Aktualnie będziemy implementować zakres Etapu III"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Zadanie 10.0: przygotowanie środowiska (0 pkt)\n",
    "\n",
    "Skopiuj potrzebny kod źródłowy z repozytorium zawierającego ostatnie zadanie (Lab 9), będziesz go używać jako bazy pod rozwiązanie poniższych zadań. \n",
    "Lista przygotowana jest pod wykonanie za pomocą pySpark (Scala Spark będzie podobna jeżeli chodzi o nazewnictwo klas), listę można zrealizować zarówno w Pythonie jak i JVM (Scala, Java, Kotlin) z wykorzystaniem Sparka bądź Flinka. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Zadanie 10.1: przygotowanie danych (1 pkt)  \n",
    "\n",
    "Przygotuj kod który pobierze dane z twojej bazy a następnie zapisze jes w formacie CSV (bądź innym który będziesz w stanie wczytać w kolejnych krokach)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Zadanie 10.2: ładowanie i podział danych (2 pkt)\n",
    "\n",
    "[Wczytaj dane](https://sparkbyexamples.com/pyspark/pyspark-read-csv-file-into-dataframe/) za pomocą pySpark oraz dokonaj ich [podziału](https://spark.apache.org/docs/3.1.1/api/python/reference/api/pyspark.sql.DataFrame.randomSplit.html)\n",
    "\n",
    "*  pySparka wykorzystujemy w trybie local, zadbaj o odpowiednią konfigurację"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Zadanie 10.3: zbuduj potok przetważania (8 pkt + 2pkt[za dodatkowe atrybuty])\n",
    "\n",
    "Zbuduj [potok przetwarzania](https://spark.apache.org/docs/latest/ml-pipeline.html#example-pipeline) który odpowiedni zmodyfikuje twój DataFrame do postaci akceptowanej przez pySpark ML, oraz nauczy model. Umożliwij predykcję dla dowolnego tekstu oraz przeprowadź predykcję na danych testowych. Dokonaj ewaluacji w oparciu o dane testowe. Wykorzystaj [miary ewaluacji](https://spark.apache.org/docs/latest/mllib-evaluation-metrics.html#ranking-systems) dla modeli regresji \n",
    "\n",
    "- dane musimy sprowadzić do postaci tabeli o kolumnach \"features\" i \"label\"\n",
    "- na podstawie cech chcemy przewidywać ilość plusów\n",
    "- wykorzystujemy LinearRegression\n",
    "- możemy wprost wykorzystać zwektoryzowany tekst\n",
    "- możemy zwektoryzować dodatkowe cechy za pomocą odpowiednich narzędzi \\[[1](https://spark.apache.org/docs/latest/ml-features.html#featurehasher), [2](https://spark.apache.org/docs/latest/ml-features.html#onehotencoder), [3](https://spark.apache.org/docs/latest/ml-features.html#stringindexer)\\] (dodatkowe punkty za dodatkowe atrybuty)\n",
    "- dodatkowo możemy [rozbudować](https://spark.apache.org/docs/latest/ml-features.html#vectorassembler) zwektroryzowany tekst o dodatkowe zwektoryzowane cechy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Zadanie 10.4: dobór parametrów (8 pkt)\n",
    "\n",
    "Stwórz kolejny potok przetwarząnia który dobierze parametry modelu regresji za pomocą podziału na [zbiór uczący i walidacyjny](https://spark.apache.org/docs/latest/ml-tuning.html#train-validation-split)\n",
    "\n",
    "* piepline może być traktowany jako estymator, przez co może być przekazany do ```TrainValidationSplit```\n",
    "* dokonaj ewaluacji najlepszego modelu na danych testowych\n",
    "* dokonaj ewaluacji modelu na danych wprowadzanych \"z palca\" (tekst jako zmienna w kodzie)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}