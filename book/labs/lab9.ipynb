{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f148c751",
   "metadata": {},
   "source": [
    "# Laboratorium 9\n",
    "\n",
    "## Implementacja mechanizmu czyszczenia i ekstrakcji cech"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7a7caff",
   "metadata": {},
   "source": [
    "Dzisiejeszym laboratorium kontynuujemy budowanie spójnego potoku masowego przetwarzania danych. Ostatnio zaimplementowaliśmy mechanizm pobierania danych, wraz z elementami monitoringu przebiegu procesu. \n",
    "\n",
    "Dzisiaj zajmiemy się przygotowaniem danych wejściowych do modelu predykcji popularności wpisu na podstawie jego treści, który implementować będziemy na kolejnych zajęciach. \n",
    "\n",
    "Diagram planowanego systemu wygląda następująco:  \n",
    "![image](../data/project_flow_chart_L9.png)\n",
    "\n",
    "Aktualnie będziemy implementować zakres Etapu II"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f12c8b4",
   "metadata": {},
   "source": [
    "### Zadanie 9.0: przygotowanie środowiska (0 pkt)\n",
    "\n",
    "Skopiuj potrzebny kod źródłowy z repozytorium zawierającego ostatnie zadanie (Lab 8), będziesz go używać jako bazy pod rozwiązanie poniższych zadań "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0a8149a",
   "metadata": {},
   "source": [
    "### Zadanie 9.1: modelowanie danych (1 pkt)  \n",
    "\n",
    "Zmodyfikuj zadanie pobierania danych:\n",
    "\n",
    "a) stwórz model danych, modelujący pojedynczy wpis, zawierający co najmniej:\n",
    "* tekst wpisu\n",
    "* ilość plusów\n",
    "* ilość komentarzy\n",
    "\n",
    "Model danych będziemy przekazywać pomiędzy zadaniami i uaktualniać jego zawartość\n",
    "\n",
    "b) przekaż każdy z pobranych wpisów oddzielnie poprzez kolejkę do kolejnego zadania. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84b9bde9",
   "metadata": {},
   "source": [
    "### Zadanie 9.2: sprawdzanie języka (2 pkt)\n",
    "\n",
    "Stwórz zadanie Celery, które będzie przyjmowało zamodelowany wpis z poprzedniego etapu.\n",
    "\n",
    "Rozpoznaj język wpisu oraz odrzuć z przetwarzania wpisy w językach innych niż polski. Użyj dowolnej metody detekcji języka, np. [langdetect](https://pypi.org/project/langdetect/) lub [fasttext](https://fasttext.cc/docs/en/language-identification.html)\n",
    "\n",
    "Zapisz statystyki detekcji języka do Grafany (w szczególności podział przetwarzanych języków)\n",
    "\n",
    "Przekaż polskie wpisy do kolejnego etapu potoku"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77eedfab",
   "metadata": {},
   "source": [
    "### Zadanie 9.3: budowanie reprezentacji wektorowej tekstu (5 pkt)\n",
    "\n",
    "Stwórz zadanie Celery, które będzie przyjmowało wpis z poprzedniego etapu.\n",
    "\n",
    "Użyj dowolnej, działającej w języku polskim metody wektoryzacji, by zbudować reprezentację jego treści.\n",
    "\n",
    "Możesz użyć:\n",
    "* tzw. _word embeddingów_ - zadbaj o odpowiednią agregację wektorów. Przykładowe modele: [Word2Vec, GloVe, ELMO](https://github.com/sdadas/polish-nlp-resources#word2vec), [FastText](https://fasttext.cc/docs/en/crawl-vectors.html), [Flair](https://github.com/flairNLP/flair)\n",
    "* modeli języka (ang. _language models_) - pamiętaj o odpowiednią agregację wektorów, jeśli to konieczne. Przykładowe modele pretrenowane do języka polskiego - [HerBERT](https://awesomeopensource.com/project/allegro/HerBERT), [Roberta](https://huggingface.co/clarin-pl/roberta-polish-kgr10) - lub modele wielojęzykowe np. [XLM-R](https://huggingface.co/xlm-roberta-base), [Labse](https://huggingface.co/sentence-transformers/LaBSE), [LASER](https://github.com/facebookresearch/LASER)\n",
    "\n",
    "Zwektoryzuj treść wpisu do formy jednego wektora, uaktualnij model danych, a następnie przekaż go do kolejnego etapu."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5457e26",
   "metadata": {},
   "source": [
    "### Zadanie 9.4: zapis danych (2 pkt)\n",
    "\n",
    "Dodaj do _docker_compose_ instancję [MongoDB](https://www.mongodb.com/compatibility/docker). Upewnij się, że ustawienia persystencji danych mają odpowiednie wartości.\n",
    "\n",
    "Stwórz task Celery, który będzie odbierał model danych z zadania wektoryzacji i zapisywał go w kolekcji Mongo.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9f311cd",
   "metadata": {},
   "source": [
    "### Zadanie 9.5: wizualizacja danych (2 pkt)\n",
    "\n",
    "Dodaj do _docker_compose_ instancję [Redash](https://redash.io/help/open-source/setup#docker)\n",
    "\n",
    "Podepnij bazę MongoDB jako źródło danych i przygotuj dashboard, który będzie przedstawiał chmurę słów (ang. _wordcloud_) dla najpopularniejszych i najmniej popularnych wpisów w ostatnim dniu - przyjmij odpowiednie progi."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
